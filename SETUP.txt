================================================================================
FASHION AI SEGMENTATION - COMPLETE SETUP GUIDE
================================================================================

This guide will help you set up and run the Fashion AI Segmentation system
after cloning the repository.

================================================================================
📁 PROJECT STRUCTURE
================================================================================

After cloning the repository, you will have the following structure:

fashion-ai-segmentation/
│
├── app/                              # Main application directory
│   ├── main.py                       # FastAPI server with web GUI
│   │                                 # - Handles image uploads
│   │                                 # - Processes images through pipeline
│   │                                 # - Serves web interface and API
│   │
│   ├── requirements.txt              # Python dependencies
│   │                                 # - FastAPI, Uvicorn
│   │                                 # - PyTorch, Transformers
│   │                                 # - OpenCV, NumPy, Pillow
│   │                                 # - Segment Anything (SAM)
│   │
│   ├── src/                          # Source code modules
│   │   ├── segformer_sam_auto_center.py
│   │   │                             # Main pipeline orchestrator
│   │   │                             # - Loads SegFormer model
│   │   │                             # - Loads SAM predictor
│   │   │                             # - Processes images end-to-end
│   │   │
│   │   ├── segformer_sam_extractor.py
│   │   │                             # Segmentation extraction logic
│   │   │                             # - SegFormer inference
│   │   │                             # - SAM mask refinement
│   │   │                             # - Mask post-processing
│   │   │
│   │   └── postprocess_center_crops.py
│   │                                 # Auto-centering algorithm
│   │                                 # - Centers detected garments
│   │                                 # - Crops individual items
│   │                                 # - Saves cropped images
│   │
│   ├── data/                         # Model weights directory
│   │   └── models/                   # ⚠️ YOU NEED TO CREATE THIS
│   │       └── sam_vit_b_01ec64.pth  # SAM model (download required)
│   │
│   ├── outputs/                      # Processing results (auto-created)
│   │   ├── {image_name}_original.jpg
│   │   ├── {image_name}_visualization.png
│   │   ├── masks_raw/                # Raw SegFormer masks
│   │   ├── masks_refined/            # SAM-refined masks
│   │   └── crops_centered/           # Individual garment crops
│   │
│   └── temp_uploads/                 # Temporary upload storage
│
├── Dockerfile                        # Docker configuration
├── .gitignore                        # Git ignore rules
├── README.md                         # Project documentation
└── SETUP.txt                         # This file

================================================================================
🔧 PREREQUISITES
================================================================================

1. Python 3.10 or higher
   - Check: python --version

2. pip (Python package manager)
   - Check: pip --version

3. Git
   - Check: git --version

4. (Optional) CUDA-capable GPU
   - For faster processing
   - CPU mode works but is slower

5. (Optional) Docker
   - For containerized deployment
   - Check: docker --version

================================================================================
📥 INSTALLATION METHODS
================================================================================

Choose ONE of the following methods:

────────────────────────────────────────────────────────────────────────────────
METHOD 1: DOCKER (EASIEST - RECOMMENDED FOR BEGINNERS)
────────────────────────────────────────────────────────────────────────────────

This method uses the pre-built Docker image from Docker Hub.
No setup required - everything is included!

Step 1: Pull the Docker image
   docker pull srinivassivakumar123/fashion-ai-segmentation

Step 2: Run the container
   docker run -p 8080:8080 srinivassivakumar123/fashion-ai-segmentation

Step 3: Open your browser
   Navigate to: http://localhost:8080

✅ DONE! The application is ready to use.

────────────────────────────────────────────────────────────────────────────────
METHOD 2: MANUAL SETUP FROM GITHUB (FOR DEVELOPERS)
────────────────────────────────────────────────────────────────────────────────

This method sets up the application from source code.

Step 1: Clone the repository
   git clone https://github.com/srinivassivakumar/fashion-ai-segmentation.git
   cd fashion-ai-segmentation

Step 2: Navigate to app directory
   cd app

Step 3: Create a virtual environment (recommended)
   # On Windows:
   python -m venv venv
   .\venv\Scripts\activate
   
   # On macOS/Linux:
   python3 -m venv venv
   source venv/bin/activate

Step 4: Install dependencies
   pip install -r requirements.txt
   
   Note: This will take 5-10 minutes as it downloads:
   - PyTorch (large package)
   - Transformers and HuggingFace models
   - Segment Anything (SAM) from GitHub
   - OpenCV and other image processing libraries

Step 5: Create model directory
   # On Windows:
   mkdir data\models
   
   # On macOS/Linux:
   mkdir -p data/models

Step 6: Download SAM model weights
   Option A - Using wget (Linux/macOS/Git Bash on Windows):
   wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O data/models/sam_vit_b_01ec64.pth
   
   Option B - Using curl:
   curl -L https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -o data/models/sam_vit_b_01ec64.pth
   
   Option C - Manual download:
   1. Go to: https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
   2. Save file to: app/data/models/sam_vit_b_01ec64.pth
   
   ⚠️ File size: ~375 MB - download may take several minutes

Step 7: Run the application
   python main.py
   
   You should see:
   [INFO] Loading SegFormer model...
   [INFO] Loading SAM predictor...
   [INFO] Starting FastAPI server...
   INFO:     Uvicorn running on http://0.0.0.0:8080

Step 8: Open your browser
   Navigate to: http://localhost:8080

✅ DONE! The application is ready to use.

────────────────────────────────────────────────────────────────────────────────
METHOD 3: BUILD DOCKER IMAGE LOCALLY (FOR CUSTOMIZATION)
────────────────────────────────────────────────────────────────────────────────

This method builds a Docker image from the source code.

Step 1: Clone the repository
   git clone https://github.com/srinivassivakumar/fashion-ai-segmentation.git
   cd fashion-ai-segmentation

Step 2: Build Docker image
   docker build -t fashion-ai-segmentation .
   
   Note: This will take 10-20 minutes on first build

Step 3: Run the container
   docker run -p 8080:8080 fashion-ai-segmentation

Step 4: Open your browser
   Navigate to: http://localhost:8080

✅ DONE! The application is ready to use.

================================================================================
🚀 USING THE APPLICATION
================================================================================

Once the server is running, you can use it in two ways:

────────────────────────────────────────────────────────────────────────────────
WEB INTERFACE (GUI)
────────────────────────────────────────────────────────────────────────────────

1. Open browser: http://localhost:8080

2. You'll see a web interface with an upload button

3. Click "Choose File" or drag-and-drop an image
   - Supported formats: JPEG, PNG
   - Recommended size: < 2000x2000 pixels for faster processing

4. Click "Upload and Process"

5. Wait for processing (2-20 seconds depending on image size and hardware)

6. View results:
   - Original image
   - Segmentation visualization
   - Individual garment crops (automatically centered)

────────────────────────────────────────────────────────────────────────────────
API INTERFACE (PROGRAMMATIC)
────────────────────────────────────────────────────────────────────────────────

POST /upload - Upload and process an image

Example using curl:
   curl -X POST -F "file=@/path/to/image.jpg" http://localhost:8080/upload

Example using Python:
   import requests
   
   url = "http://localhost:8080/upload"
   files = {"file": open("image.jpg", "rb")}
   response = requests.post(url, files=files)
   print(response.json())

GET /results/{image_name} - View processing results

Example:
   http://localhost:8080/results/my_outfit.jpg

GET /outputs/{path} - Download specific output file

Example:
   http://localhost:8080/outputs/crops_centered/my_outfit_upper_clothes_2.png

================================================================================
📊 OUTPUT FILES EXPLAINED
================================================================================

After processing an image named "outfit.jpg", you'll get:

1. outputs/outfit_original.jpg
   - The original uploaded image (preserved)

2. outputs/outfit_visualization.png
   - Segmentation overlay showing detected garments in different colors

3. outputs/masks_raw/outfit_segformer_raw.png
   - Raw segmentation mask from SegFormer model
   - Each pixel value represents a garment class (0-12)

4. outputs/masks_refined/outfit_sam_refined.png
   - Refined mask after SAM processing
   - More precise boundaries around garments

5. outputs/crops_centered/outfit_hat_1.png
   - Cropped and centered hat (if detected)

6. outputs/crops_centered/outfit_upper_clothes_2.png
   - Cropped and centered shirt/top (if detected)

7. outputs/crops_centered/outfit_pants_4.png
   - Cropped and centered pants (if detected)

... and so on for each detected garment class

================================================================================
👕 DETECTED GARMENT CLASSES
================================================================================

The system can detect and segment 13 fashion categories:

Class 0:  Background (ignored)
Class 1:  Hat
Class 2:  Upper Clothes (shirts, t-shirts, jackets, hoodies, etc.)
Class 3:  Skirt
Class 4:  Pants (jeans, trousers, shorts, etc.)
Class 5:  Dress
Class 6:  Belt
Class 7:  Left Shoe
Class 8:  Right Shoe
Class 9:  Face (detected but not cropped)
Class 10: Left Leg (detected but not cropped)
Class 11: Right Leg (detected but not cropped)
Class 12: Left Arm (detected but not cropped)
Class 13: Right Arm (detected but not cropped)

Note: Only wearable items (classes 1-8) are cropped and saved individually.
Body parts are used for context but not extracted.

================================================================================
⚙️ CONFIGURATION
================================================================================

You can customize the pipeline by editing:

app/src/segformer_sam_auto_center.py

Key configuration options in the Config class:

- MODEL_NAME: SegFormer model to use
- SAM_CHECKPOINT: Path to SAM model weights
- DEVICE: "cuda" (GPU) or "cpu"
- OUTPUT_DIR: Where to save results
- CONFIDENCE_THRESHOLD: Minimum confidence for detections

================================================================================
❓ TROUBLESHOOTING
================================================================================

Problem: "Module not found" errors
Solution: Make sure you're in the app/ directory and virtual environment
          is activated. Re-run: pip install -r requirements.txt

Problem: "SAM model not found"
Solution: Download the SAM model weights as described in Step 6 of Method 2
          File should be at: app/data/models/sam_vit_b_01ec64.pth

Problem: "CUDA out of memory"
Solution: Your GPU doesn't have enough VRAM. The application will
          automatically fall back to CPU mode, or you can:
          - Resize images to smaller dimensions
          - Close other GPU-intensive applications

Problem: "Processing is very slow"
Solution: This is normal on CPU. Expected times:
          - GPU: 2-5 seconds per image
          - CPU: 10-30 seconds per image
          Consider using the Docker image or enabling GPU support.

Problem: "Port 8080 already in use"
Solution: Another application is using port 8080. Either:
          - Stop the other application
          - Change the port in main.py (look for uvicorn.run)
          - Run with custom port: uvicorn main:app --port 8081

Problem: "Image quality is poor in crops"
Solution: Upload higher resolution images. The system preserves
          original quality but small input images will have small crops.

Problem: "No garments detected"
Solution: Make sure the image contains visible clothing items.
          Try with a well-lit image showing clear garments.

================================================================================
🔒 SECURITY NOTES
================================================================================

1. The server runs on 0.0.0.0:8080 (accessible from network)
   - For production, add authentication
   - Use HTTPS in production environments
   - Consider firewall rules

2. Uploaded images are stored temporarily
   - Files are saved in temp_uploads/
   - Consider implementing cleanup routines

3. No data is sent to external services
   - All processing happens locally
   - Models run on your machine
   - No cloud API calls required

================================================================================
📈 PERFORMANCE TIPS
================================================================================

1. Use GPU if available
   - 5-10x faster than CPU
   - Install CUDA toolkit for GPU support

2. Optimize image sizes
   - Resize images to 1024x1024 for balance between speed and quality
   - Very large images (>4000px) can be slow

3. Batch processing
   - Modify main.py to process multiple images
   - Reuse loaded models (don't reload for each image)

4. Docker optimization
   - Use --gpus all flag for GPU support in Docker:
     docker run --gpus all -p 8080:8080 fashion-ai-segmentation

================================================================================
🛠️ DEVELOPMENT
================================================================================

To modify or extend the system:

1. Fork the repository on GitHub

2. Make your changes in the src/ directory

3. Test locally using Method 2 (manual setup)

4. Submit a pull request

Key files to modify:
- app/main.py: API endpoints and web interface
- app/src/segformer_sam_auto_center.py: Main pipeline logic
- app/src/segformer_sam_extractor.py: Segmentation algorithms
- app/src/postprocess_center_crops.py: Cropping and centering logic

================================================================================
📚 ADDITIONAL RESOURCES
================================================================================

- SegFormer Paper: https://arxiv.org/abs/2105.15203
- SAM Paper: https://arxiv.org/abs/2304.02643
- FastAPI Docs: https://fastapi.tiangolo.com/
- PyTorch Docs: https://pytorch.org/docs/

================================================================================
💬 SUPPORT
================================================================================

For issues, questions, or contributions:

GitHub Issues: https://github.com/srinivassivakumar/fashion-ai-segmentation/issues
Docker Hub: https://hub.docker.com/r/srinivassivakumar123/fashion-ai-segmentation

Please provide:
- Operating system and version
- Python version
- Error messages (full traceback)
- Steps to reproduce the issue

================================================================================
📄 LICENSE
================================================================================

MIT License - See README.md for details

================================================================================

Happy Fashion Segmentation! 👗👔👠

================================================================================
